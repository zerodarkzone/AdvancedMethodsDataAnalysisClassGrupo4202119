{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "\n",
    "# Movie Genre Classification\n",
    "\n",
    "Classify a movie genre based on its plot.\n",
    "\n",
    "<img src=\"moviegenre.png\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/miia4201-202019-p3-moviegenreclassification/overview\n",
    "\n",
    "### Data\n",
    "\n",
    "Input:\n",
    "- movie plot\n",
    "\n",
    "Output:\n",
    "- Probability of the movie belonging to each genre\n",
    "\n",
    "\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "We thank Professor Fabio Gonzalez, Ph.D. and his student John Arevalo for providing this dataset.\n",
    "\n",
    "See https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de géneros de películas\n",
    "\n",
    "En este documento se intentará realizar una predicción de los géneros de algunas películas basados en el resumen o sinopsis de las películas. Para ello se tienen en cuenta las variables plot, Year y title con las cuales por medio de lo escrito en cada registro se realiza una transformación vectorizando cada palabra que describe la película.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue de información \n",
    "\n",
    "dataTraining = pd.read_csv('https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/raw/master/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/raw/master/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>['Short', 'Drama']</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1941</td>\n",
       "      <td>A Woman's Face</td>\n",
       "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
       "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>1954</td>\n",
       "      <td>Executive Suite</td>\n",
       "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>1990</td>\n",
       "      <td>Narrow Margin</td>\n",
       "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "6724  1941             A Woman's Face   \n",
       "4704  1954            Executive Suite   \n",
       "2582  1990              Narrow Margin   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "6724  in sweden ,  a female blackmailer with a disfi...   \n",
       "4704  in a friday afternoon in new york ,  the presi...   \n",
       "2582  in los angeles ,  the editor of a publishing h...   \n",
       "\n",
       "                                  genres  rating  \n",
       "3107                  ['Short', 'Drama']     8.0  \n",
       "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
       "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
       "4704                           ['Drama']     7.4  \n",
       "2582     ['Action', 'Crime', 'Thriller']     6.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estructura de los datos a trabajar  - Train\n",
    "\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Message in a Bottle</td>\n",
       "      <td>who meets by fate ,  shall be sealed by fate ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>Midnight Express</td>\n",
       "      <td>the true story of billy hayes ,  an american c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>Primal Fear</td>\n",
       "      <td>martin vail left the chicago da ' s office to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1950</td>\n",
       "      <td>Crisis</td>\n",
       "      <td>husband and wife americans dr .  eugene and mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959</td>\n",
       "      <td>The Tingler</td>\n",
       "      <td>the coroner and scientist dr .  warren chapin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                title  \\\n",
       "1  1999  Message in a Bottle   \n",
       "4  1978     Midnight Express   \n",
       "5  1996          Primal Fear   \n",
       "6  1950               Crisis   \n",
       "7  1959          The Tingler   \n",
       "\n",
       "                                                plot  \n",
       "1  who meets by fate ,  shall be sealed by fate ....  \n",
       "4  the true story of billy hayes ,  an american c...  \n",
       "5  martin vail left the chicago da ' s office to ...  \n",
       "6  husband and wife americans dr .  eugene and mr...  \n",
       "7  the coroner and scientist dr .  warren chapin ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estructura de los datos a evaluar  - Test\n",
    "\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación  vectorización de conteo\n",
    "\n",
    "Para representar datos de texto de manera númerica, se usa una codificación única de las palabras por medio de la vectorización, en ello se va a limitar a 1.000 la cantidad de vectores que se van a imprimir. \n",
    "\n",
    "Por medio de la función \"fit_transform\" en la variable __plot__ obtenemos una base con dimensiones de 7.895 filas y 1.000 columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7895, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features=1000) \n",
    "X_dtm = vect.fit_transform(dataTraining['plot'])\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'about', 'accepts', 'accident', 'accidentally', 'across', 'act', 'action', 'actor', 'actress', 'actually', 'adam', 'adult', 'adventure', 'affair', 'after', 'again', 'against', 'age', 'agent', 'agents', 'ago', 'agrees', 'air', 'alan', 'alex', 'alice', 'alien', 'alive', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'america', 'american', 'among', 'an', 'and', 'angeles', 'ann', 'anna', 'another', 'any', 'anyone', 'anything', 'apartment']\n"
     ]
    }
   ],
   "source": [
    "# Primeras 50 palabras con mas frecuencia en la variable plot.\n",
    "\n",
    "print(vect.get_feature_names()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obteniendo los 50 vectores con mas frecuencia, observamos que palabras como _able_, _about_, _accepts_ son las de las más repetivivas en resumenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la variable y\n",
    "\n",
    "\n",
    "Como la variable a predecir son los géneros de las películas, la variable __y__ debe expresarse como una matriz binaria dentro de géneros que puede tener el filme, lo que hace que sea más fácil el procesamiento de la información. Es importante saber que una película puede tener uno o más géneros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variable Y\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "\n",
    "# Binarización de las múltiples etiquetas o géneros que puede contener una película\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train de las multiclases en las multietiquetas de modelo.\n",
    "\n",
    "Se usa la estrategi a One vs Rest para la clasificación de múltiples etiquetas, donde se divide una clasificación de múltiples etiquetas o géneros, en múltiples problemas de clasificación binaria por cada etiqueta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Evaluación modelo - Random forest para clasificación de los géneros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_genres = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7812262183677007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se usa predict_proba en lugar de solo predict, para que el resultado de la predicción no sea 1 o 0 como clasificación binaria para los géneros de cada película, sino la probabilidad de que una película se asocie con un género, es decir, la probabilidad asociada a que tome la etiqueta o genero la película que tratamos de predecir.\n",
    "\n",
    "* El AUC de los datos de validación generados con el modelo anterior nos arroja una predicción del 0.7812. La cual no se percibe como una buena predicción para los datos entrenados en la cual el género o los géneros asociados a la película podría fallar repetidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción de los datos del test \n",
    "\n",
    "Luego de realizar la validación del modelo de los datos de train, contra los datos de test sin vectorizar, obtenemos una estimación de AUC. Ahora Vectorizamos los datos del test transformandolos en categorías o variables los géneros que pueden contener las películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(dataTesting['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = clf.predict_proba(X_test_dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143030</td>\n",
       "      <td>0.101960</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.354552</td>\n",
       "      <td>0.138830</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>0.490140</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.056648</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.018117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122624</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>0.080359</td>\n",
       "      <td>0.515684</td>\n",
       "      <td>0.062976</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.060935</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.149703</td>\n",
       "      <td>0.058190</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.018506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.151364</td>\n",
       "      <td>0.110284</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.304837</td>\n",
       "      <td>0.448736</td>\n",
       "      <td>0.021010</td>\n",
       "      <td>0.611544</td>\n",
       "      <td>0.081741</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044538</td>\n",
       "      <td>0.261372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335987</td>\n",
       "      <td>0.128505</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.423242</td>\n",
       "      <td>0.052693</td>\n",
       "      <td>0.025351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.154448</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.064124</td>\n",
       "      <td>0.340779</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131074</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197224</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.269385</td>\n",
       "      <td>0.077607</td>\n",
       "      <td>0.017862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175143</td>\n",
       "      <td>0.210069</td>\n",
       "      <td>0.035476</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>0.243150</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.079781</td>\n",
       "      <td>0.143879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.090359</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.205117</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.017585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.143030     0.101960     0.024454     0.029938  0.354552  0.138830   \n",
       "4  0.122624     0.085786     0.024213     0.084795  0.370949  0.216657   \n",
       "5  0.151364     0.110284     0.013762     0.075334  0.304837  0.448736   \n",
       "6  0.154448     0.125772     0.020991     0.064124  0.340779  0.140892   \n",
       "7  0.175143     0.210069     0.035476     0.032505  0.313850  0.243150   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.030787  0.490140  0.073159   0.101339  ...   0.025069   0.063208   \n",
       "4       0.080359  0.515684  0.062976   0.067019  ...   0.024734   0.060935   \n",
       "5       0.021010  0.611544  0.081741   0.169121  ...   0.044538   0.261372   \n",
       "6       0.009133  0.632038  0.068287   0.063631  ...   0.131074   0.088418   \n",
       "7       0.021793  0.427885  0.079781   0.143879  ...   0.023859   0.090359   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000000   0.362818  0.056648  0.008970  0.017522    0.202605  0.033989   \n",
       "4  0.000477   0.149703  0.058190  0.014248  0.020099    0.204794  0.030438   \n",
       "5  0.000000   0.335987  0.128505  0.001016  0.048658    0.423242  0.052693   \n",
       "6  0.000000   0.197224  0.132208  0.001432  0.039743    0.269385  0.077607   \n",
       "7  0.000048   0.205117  0.241663  0.002634  0.018403    0.259465  0.021569   \n",
       "\n",
       "   p_Western  \n",
       "1   0.018117  \n",
       "4   0.018506  \n",
       "5   0.025351  \n",
       "6   0.017862  \n",
       "7   0.017585  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('pred_genres_text_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2606, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Modelo LightGBM para evaluación de género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LGBMClassifier(random_seed=42))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier( LGBMClassifier( random_seed=42 ) )\n",
    "clf.fit(X_train.astype('float64'), y_train_genres.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978773764704655"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_genres = clf.predict_proba(X_test.astype('float64'))\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparados por el AUC, los modelos de Random Forest y LGMB dan __0.7812__ y __0.7978__ respectivamente, siendo el segundo un poco mejor pero no significativamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Usar un pipeline para evitar data leakage:\n",
    "\n",
    "Como observamos anteriormente el modelo LGBM tiene una mejor predicción, pero tenemos que buscar los mejores parametros que se ajusten a la predicción, para ellos usamos pipeline para que el modelo los memorice y repita los pasos que especificamos para que realice el procesamiento de nuevos datos en el orden indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataTraining.drop(columns=['genres','rating']).reset_index(drop=True)\n",
    "y = dataTraining['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = MultiLabelBinarizer()\n",
    "y_train_genres_mlb = le.fit_transform(y_train_genres)\n",
    "y_test_genres_mlb = le.transform(y_test_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = Pipeline(steps=[('vectorizer', CountVectorizer())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('txt_title', text_transformer, 'title'),\n",
    "                 ('txt_plot', text_transformer, 'plot')], remainder='passthrough', sparse_threshold = 0 )\n",
    "\n",
    "clf = Pipeline([('preprocessor', preprocessor ),\n",
    "               ('classifier', OneVsRestClassifier( LGBMClassifier( random_seed=42 )))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n",
       "                                   transformers=[('txt_title',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer())]),\n",
       "                                                  'title'),\n",
       "                                                 ('txt_plot',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer())]),\n",
       "                                                  'plot')])),\n",
       "                ('classifier',\n",
       "                 OneVsRestClassifier(estimator=LGBMClassifier(random_seed=42)))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train_genres_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695510005598357"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres_mlb, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto al LGBM entrenado en el paso __2__ se observa una mejora importante en la predicción usando Pipeline, en donde se pasa de un AUC de 0.79 a 0.87. La ganancia en la predicción fue de 10 % con respecto al anterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Fine tunning de parámetros para mejorar el score\n",
    "\n",
    "Por medio de este método realizamos una grilla con múltiples condiciones en cada parámetro, buscando los mejores dentro de las condiciones establecidas y que se muestran a continuación.\n",
    "\n",
    "Luego evaluamos promedio del HavingRamdomsearch el modelo LGBM teniendo encuenta lo siguiente:\n",
    "\n",
    "* CLF = Modelo LGBM\n",
    "* param_grid = Grilla con los multiparametros establecidos\n",
    "* n_candidates = exhaust, metodo de evaluación exhaustivo ejecutando múltiples muestras de todos los parametros.\n",
    "* factor = 4 aumento de recursos al ir encontrando los mejores parametros\n",
    "* scoring = neg_log_loss, puntaje usado para evaluar los modelos.\n",
    "* cv = 5, número de folds escogidos.\n",
    "* random_state = Semilla utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__estimator__num_leaves\": [20, 31, 50, 100],\n",
    "    \"classifier__estimator__max_depth\": [-1, 3, 6, 15, 20, 25, 50],\n",
    "    \"classifier__estimator__learning_rate\": [0.05, 0.075, 0.1, 0.2, 0.3, 0.45, 0.4, 0.6],\n",
    "    \"classifier__estimator__n_estimators\": [50, 100, 1000, 1500],\n",
    "    \"classifier__estimator__subsample_for_bin\": [100000, 200000, 250000, 300000],\n",
    "    \"classifier__estimator__min_split_gain\": [0.0, 0.3, 0.4, 0.1, 0.5, 0.7, 0.9],\n",
    "    \"classifier__estimator__min_child_samples\": [10, 20, 30, 50],\n",
    "    \"classifier__estimator__subsample\": [0.7, 0.8, 0.9, 1],\n",
    "    \"classifier__estimator__reg_alpha\": [0.0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    \"classifier__estimator__reg_lambda\": [0.0, 0.01, 0.03, 0.05, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "search = HalvingRandomSearchCV(clf,\n",
    "                               param_grid,\n",
    "                               n_candidates='exhaust',\n",
    "                               factor=4,\n",
    "                               scoring='neg_log_loss',\n",
    "                               n_jobs=2,\n",
    "                               cv=5,\n",
    "                               random_state=0).fit(X_train, y_train_genres_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LGBMClassifierSearch2.pkl\", \"wb\") as model:\n",
    "    pickle.dump(search, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8671279762876454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_genres = search.predict_proba(X_test)\n",
    "roc_auc_score(y_test_genres_mlb, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando realizamos el fine tunning al modelo, observamos que no existe una mejora en en AUC en los datos de entrenamiento que con el metodo con Pipeline. Sin embargo al realizar la prueba con los datos de test en __Kaggle__, se observa una mejora que con solo el Pipeline pasando de un AUC de 0.86 a 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Entrenar con todo el dataset\n",
    "\n",
    "Luego de observar la mejor metodología con los mejores parametros para obtener una mejor predicción en los géneros que puede contener una película, se debe tomar la mayor cantidad de datos posibles. Para ello se genera el entrenamiento del módelo con todos los datos que contenia la base original de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator__subsample_for_bin': 100000,\n",
       " 'classifier__estimator__subsample': 1,\n",
       " 'classifier__estimator__reg_lambda': 0.3,\n",
       " 'classifier__estimator__reg_alpha': 0.2,\n",
       " 'classifier__estimator__num_leaves': 31,\n",
       " 'classifier__estimator__n_estimators': 1000,\n",
       " 'classifier__estimator__min_split_gain': 0.9,\n",
       " 'classifier__estimator__min_child_samples': 30,\n",
       " 'classifier__estimator__max_depth': 15,\n",
       " 'classifier__estimator__learning_rate': 0.075}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = MultiLabelBinarizer()\n",
    "y_genres_mlb = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n",
       "                                   transformers=[('txt_title',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer())]),\n",
       "                                                  'title'),\n",
       "                                                 ('txt_plot',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer())]),\n",
       "                                                  'plot')])),\n",
       "                ('classifier',\n",
       "                 OneVsRestClassifier(estimator=LGBMClassifier(learning_rate=0.075,\n",
       "                                                              max_depth=15,\n",
       "                                                              min_child_samples=30,\n",
       "                                                              min_split_gain=0.9,\n",
       "                                                              n_estimators=1000,\n",
       "                                                              random_seed=42,\n",
       "                                                              reg_alpha=0.2,\n",
       "                                                              reg_lambda=0.3,\n",
       "                                                              subsample=1,\n",
       "                                                              subsample_for_bin=100000)))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.fit(X, y_genres_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = dataTesting\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_test_genres = best_clf.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080779</td>\n",
       "      <td>0.081010</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.015201</td>\n",
       "      <td>0.482351</td>\n",
       "      <td>0.043803</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.466669</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.227760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.681506</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.207888</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.219639</td>\n",
       "      <td>0.154151</td>\n",
       "      <td>0.199398</td>\n",
       "      <td>0.037461</td>\n",
       "      <td>0.768848</td>\n",
       "      <td>0.014970</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.030153</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.034155</td>\n",
       "      <td>0.027519</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.157489</td>\n",
       "      <td>0.019946</td>\n",
       "      <td>0.008266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.068823</td>\n",
       "      <td>0.864988</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.829131</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.663614</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.118779</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.506973</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.061144</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.808748</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.098987</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.185578</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.322705</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.004030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.060829</td>\n",
       "      <td>0.108544</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.023578</td>\n",
       "      <td>0.130385</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.143484</td>\n",
       "      <td>0.054584</td>\n",
       "      <td>0.307141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.035613</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.132674</td>\n",
       "      <td>0.679945</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.179092</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.004142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.080779     0.081010     0.013310     0.015201  0.482351  0.043803   \n",
       "4  0.075900     0.012322     0.005079     0.219639  0.154151  0.199398   \n",
       "5  0.002244     0.002133     0.000566     0.013261  0.068823  0.864988   \n",
       "6  0.011534     0.038582     0.001378     0.013702  0.061144  0.045907   \n",
       "7  0.060829     0.108544     0.001746     0.023578  0.130385  0.018912   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.001697  0.466669  0.048681   0.227760  ...   0.008372   0.009357   \n",
       "4       0.037461  0.768848  0.014970   0.012125  ...   0.024042   0.030153   \n",
       "5       0.001203  0.829131  0.000712   0.006282  ...   0.000930   0.663614   \n",
       "6       0.000747  0.808748  0.006504   0.012686  ...   0.008190   0.098987   \n",
       "7       0.000884  0.143484  0.054584   0.307141  ...   0.010135   0.035613   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000158   0.681506  0.011398  0.001237  0.003685    0.207888  0.002959   \n",
       "4  0.000158   0.034155  0.027519  0.007203  0.007469    0.157489  0.019946   \n",
       "5  0.000176   0.118779  0.021720  0.000669  0.001207    0.506973  0.002633   \n",
       "6  0.000158   0.039352  0.185578  0.000430  0.002071    0.322705  0.019989   \n",
       "7  0.000158   0.132674  0.679945  0.000900  0.001601    0.179092  0.002772   \n",
       "\n",
       "   p_Western  \n",
       "1   0.001729  \n",
       "4   0.008266  \n",
       "5   0.000687  \n",
       "6   0.004030  \n",
       "7   0.004142  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('pred_genres_text_RF.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentarios\n",
    "\n",
    "* El modelo LGBM presenta buenos resultados en las predicciones, sin embargo al realizar tunning en sus paramatros se obtienen mejorar considerables en su poder predictivo\n",
    "\n",
    "* Realizar el procedimiento en el orden indicado anteriormente genera que al final, con la totalidad de los datos que tenemos el poder predictivo del modelo sea consideramblemente mejor, incluso mejorando el AUC con los datos de test en la competencia en kaggle\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
